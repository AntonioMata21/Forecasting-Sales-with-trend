{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18599,"databundleVersionId":1236839,"sourceType":"competition"},{"sourceId":79133004,"sourceType":"kernelVersion"},{"sourceId":79133251,"sourceType":"kernelVersion"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv\")\ndatax=df.sample(n=300, random_state=123)\ndatax.set_index('id',inplace=True)\n\ndatax=datax.iloc[:,-1941:]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_split(data, n_test):\n    return data[:-n_test, :], data[-n_test:, :]\n\ndef calculate_zeros_percentage(arr):\n    num_zeros = np.count_nonzero(arr == 0)\n    total_elements = arr.size\n    zeros_percentage = (num_zeros / total_elements) * 100\n    return zeros_percentage\n    \ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols = list()\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n    agg = pd.concat(cols, axis=1)\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg.values\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\ndef prediction_plot(testY, test_predict):\n\n    len_prediction=[x for x in range(len(testY))]\n    plt.figure(figsize=(8,4))\n    plt.plot(len_prediction, testY[:len(testY)], marker='.', label=\"actual\")\n    plt.plot(len_prediction, test_predict[:len(testY)], 'r', label=\"prediction\")\n    plt.tight_layout()\n    sns.despine(top=True)\n    plt.subplots_adjust(left=0.07)\n    plt.ylabel('Pred Trend', size=15)\n    plt.xlabel('Time step', size=15)\n    plt.legend(fontsize=15)\n    plt.show();\n    \ndef smape(a, f):\n    a = np.array([float(val) for val in a])\n    f = np.array([float(val) for val in f])\n    \n    numerator = 2 * np.abs(f - a)\n    denominator = np.abs(a) + np.abs(f)\n    \n    return 100 / len(a) * np.sum(numerator / denominator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n        \"objective\": \"poisson\",\n        \"metric\": \"poisson\",\n        \"learning_rate\": 0.09,\n        \"sub_feature\": 0.9,\n        \"sub_row\": 0.75,\n        \"bagging_freq\": 1,\n        \"lambda_l2\": 0.1,\n        'verbosity': 1,\n        'num_iterations': 2000,\n        'num_leaves': 32,\n        \"min_data_in_leaf\": 50,\n            }\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\nsmapeList=[]\npredsList=[]\nfor i in range(300):\n    print(\"-----------------------\",i,\"-------------------------------\")\n    \n    #MA=datax.iloc[[i][0]].rolling(window=5).mean().dropna()\n    nMA=datax.iloc[[i][0]]\n    values =nMA.values\n    \n    # transform the time series data into supervised learning\n    values= np.array(values).reshape(-1, 1)\n    data = series_to_supervised(values, n_in=6)\n    train, test = train_test_split(data, 28)\n    train = np.asarray(train)\n    trainX, trainY = train[:, :-1], train[:, -1]\n    testX, testY= test[:, :-1], test[:, -1]\n    train_data = lgb.Dataset(trainX, label=trainY)\n    valid_data = lgb.Dataset(testX, label=testY)\n    m_lgb = lgb.train(params, train_data, valid_sets=[train_data, valid_data],\n                      verbose_eval=20, early_stopping_rounds=30,num_boost_round = 3600)\n    \n    preds=m_lgb.predict(testX)\n    \n    smapeList.append(smape(testY,preds))\n    predsList.append(preds)\n    \n    print('----------------------predic test----------------------------')\n    prediction_plot(testY,preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idsx=datax.index.tolist()\n# Crear un DataFrame\nids=idsx\n\ndf = pd.DataFrame(predsList)\ndf['id'] = ids\ndf.set_index('id', inplace=True)\n# Guardar el DataFrame en un archivo CSV\ndf.to_csv('preds_lgbm_300sOrginal.csv', index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p= sum(smapeList)/len(smapeList)\nsp=round(p,2)\nprint('sMape promedio: ',sp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfr= pd.DataFrame(smapeList)\ndfr.to_csv(\"Results_lgbm_300s.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}