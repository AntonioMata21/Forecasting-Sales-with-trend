{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18599,"databundleVersionId":1236839,"sourceType":"competition"},{"sourceId":7614531,"sourceType":"datasetVersion","datasetId":3730156},{"sourceId":79133004,"sourceType":"kernelVersion"},{"sourceId":79133251,"sourceType":"kernelVersion"}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":356.223713,"end_time":"2024-01-11T18:30:54.233903","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-11T18:24:58.010190","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.95066,"end_time":"2024-01-11T18:25:02.729863","exception":false,"start_time":"2024-01-11T18:25:01.779203","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv\")\ndatax=df.sample(n=300, random_state=123)\ndatax.set_index('id',inplace=True)\n\ndatax=datax.iloc[:,-1941:]","metadata":{"papermill":{"duration":4.676749,"end_time":"2024-01-11T18:25:07.412652","exception":false,"start_time":"2024-01-11T18:25:02.735903","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef compare_lists(list1, list2):\n    \"\"\"\n    Compara dos listas de diferentes tamaños y cuenta la tendencia de la lista mayor.\n    Retorna \"tendencia al alza\" si list1 tiene más valores mayores que list2,\n    \"tendencia a la baja\" si list2 tiene más valores mayores que list1,\n    y \"empate\" si ambos tienen la misma cantidad de valores mayores.\n    \"\"\"\n    list1 = list1.values.tolist()\n    list2 = list2.values.tolist()\n    min_len = min(len(list1), len(list2))    \n    # Reducir las listas al tamaño del menor\n    list1 = list1[:min_len]   \n    list2 = list2[:min_len]    \n    # Buscar el primer índice donde ambas listas tengan valores no nulos\n    i = 0\n    while i < min_len and (np.isnan(list1[i]) or np.isnan(list2[i])):\n        i += 1\n        \n    # Comparar valores de ambas listas a partir del índice encontrado\n    count_a = 0\n    count_b = 0\n    for j in range(i, min_len):        \n        if list1[j] > list2[j]:\n            count_a += 1\n        elif list2[j] > list1[j]:\n            count_b += 1\n    dif=abs(count_a-count_b)\n    umbral = 3\n    if dif >= umbral:\n        if count_a > count_b:\n            return [\"tendencia al alza\", count_a ,count_b]\n        \n        elif count_b > count_a:\n            return [\"tendencia a la baja\", count_a ,count_b]\n    else:\n        return [\"no tiene tendencia\", count_a, count_b]\n    \ndef plot_moving_averages(data, window1, window2):\n    \"\"\"\n    Calcula y grafica dos promedios móviles de una serie de tiempo.\n    data: la serie de tiempo a procesar.\n    window1: el tamaño de la ventana del primer promedio móvil.\n    window2: el tamaño de la ventana del segundo promedio móvil.\n    \"\"\"\n    #plt.figure(figsize=(16,8))\n    xlabel='Horizonte de Tiempo'\n    ylabel='Valor de la serie'\n    # Calcula los dos promedios móviles\n    data=pd.DataFrame(data)\n    ma1 = data.rolling(window=window1).mean()\n    ma2 = data.rolling(window=window2).mean()\n    \n    new_x_values = np.arange(len(data))\n    \n    # Grafica la serie de tiempo y los dos promedios móviles\n    \n    plt.plot(new_x_values, data, label='Original')\n    plt.plot(new_x_values, ma1,color=\"green\", label=f'MA({window1})')\n    plt.plot(new_x_values, ma2,color=\"red\", label=f'MA({window2})')\n    \n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    \n    \n    plt.legend()\n    plt.show()\n    \n    return ma1,ma2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rax=[]\ndatax2=datax.iloc[:,-30:]\nfor i in range(300):\n    m1,m2=plot_moving_averages(datax2.iloc[i],3,5)\n    rax.append([compare_lists(m1, m2), datax2.index[i]])\n    \n    print(rax[i])\n    \nnrax=[]\nfor i in range(len(rax)):\n    if(rax[i][0][0]!='no tiene tendencia'):\n        nrax.append(rax[i]) \npt=(len(nrax)/len(rax))*100\nprint(f\"{len(nrax)} series fuenron clasificadas con tendencia es decir {pt}%.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_split(data, n_test):\n    return data[:-n_test, :], data[-n_test:, :]\n\ndef calculate_zeros_percentage(arr):\n    num_zeros = np.count_nonzero(arr == 0)\n    total_elements = arr.size\n    zeros_percentage = (num_zeros / total_elements) * 100\n    return zeros_percentage\n    \ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols = list()\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n    agg = pd.concat(cols, axis=1)\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg.values\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\ndef prediction_plot(testY, test_predict):\n\n    len_prediction=[x for x in range(len(testY))]\n    plt.figure(figsize=(8,4))\n    plt.plot(len_prediction, testY[:len(testY)], marker='.', label=\"actual\")\n    plt.plot(len_prediction, test_predict[:len(testY)], 'r', label=\"prediction\")\n    plt.tight_layout()\n    sns.despine(top=True)\n    plt.subplots_adjust(left=0.07)\n    plt.ylabel('Pred Trend', size=15)\n    plt.xlabel('Time step', size=15)\n    plt.legend(fontsize=15)\n    plt.show();\n    \ndef smape(a, f):\n    a = np.array([float(val) for val in a])\n    f = np.array([float(val) for val in f])\n    \n    numerator = 2 * np.abs(f - a)\n    denominator = np.abs(a) + np.abs(f)\n    \n    return 100 / len(a) * np.sum(numerator / denominator)","metadata":{"papermill":{"duration":1.713512,"end_time":"2024-01-11T18:25:09.169603","exception":false,"start_time":"2024-01-11T18:25:07.456091","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n        \"objective\": \"poisson\",\n        \"metric\": \"poisson\",\n        \"learning_rate\": 0.09,\n        \"sub_feature\": 0.9,\n        \"sub_row\": 0.75,\n        \"bagging_freq\": 1,\n        \"lambda_l2\": 0.1,\n        'verbosity': 1,\n        'num_iterations': 2000,\n        'num_leaves': 32,\n        \"min_data_in_leaf\": 50,\n            }\n","metadata":{"papermill":{"duration":0.01458,"end_time":"2024-01-11T18:25:09.188542","exception":false,"start_time":"2024-01-11T18:25:09.173962","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\nsmapeList=[]\n\npredsList=[]\nfor i in range(len(nrax)):\n    print(\"-----------------------\",i,\"-------------------------------\")\n    \n    #MA=datax.loc[nrax[i][1]].rolling(window=5).mean().dropna()\n    nMA=datax.loc[nrax[i][1]]\n    #nMA=datax.iloc[[i][0]]\n    values =nMA.values\n    \n    # transform the time series data into supervised learning\n    values= np.array(values).reshape(-1, 1)\n    data = series_to_supervised(values, n_in=6)\n    train, test = train_test_split(data, 28)\n    train = np.asarray(train)\n    trainX, trainY = train[:, :-1], train[:, -1]\n    testX, testY= test[:, :-1], test[:, -1]\n    train_data = lgb.Dataset(trainX, label=trainY)\n    valid_data = lgb.Dataset(testX, label=testY)\n    m_lgb = lgb.train(params, train_data, valid_sets=[train_data, valid_data],\n                      verbose_eval=20, early_stopping_rounds=30,num_boost_round = 3600)\n    \n    preds=m_lgb.predict(testX)\n    smapeList.append(smape(testY,preds))\n        \n    print('----------------------predic test----------------------------')\n    predsList.append(preds)\n    prediction_plot(testY,preds)","metadata":{"papermill":{"duration":339.962637,"end_time":"2024-01-11T18:30:49.202955","exception":false,"start_time":"2024-01-11T18:25:09.240318","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Crear un DataFrame\nids=[i[1] for i in nrax]\n\ndf = pd.DataFrame(predsList)\ndf['id'] = ids\ndf.set_index('id', inplace=True)\n# Guardar el DataFrame en un archivo CSV\ndf.to_csv('preds_lgbm_130sOrginal.csv', index=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p= sum(smapeList)/len(smapeList)\nsp=round(p,2)\nprint('sMape promedio: ',sp)","metadata":{"papermill":{"duration":0.340483,"end_time":"2024-01-11T18:30:49.881694","exception":false,"start_time":"2024-01-11T18:30:49.541211","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfr= pd.DataFrame(smapeList)\ndfr.to_csv(\"Results_lgbm_130sMA5.csv\")","metadata":{"papermill":{"duration":0.342326,"end_time":"2024-01-11T18:30:50.548444","exception":false,"start_time":"2024-01-11T18:30:50.206118","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}